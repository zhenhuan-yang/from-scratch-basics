{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011e3c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c70ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28792994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some', ' text', ' that', ' i', \"'ll\", ' pre', '-', 'tokenize']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(PAT, \"some text that i'll pre-tokenize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf99501",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"low low low low low\",\n",
    "    \"lower lower widest widest widest\",\n",
    "    \"newest newest newest newest newest newest\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7169e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'newest': 6, 'low': 5, 'widest': 3, 'lower': 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import Dict, Tuple, List\n",
    "word_freq = Counter()\n",
    "for line in corpus:\n",
    "    for w in line.split():\n",
    "        word_freq[w] += 1\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb83596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- utility -----\n",
    "def split_bytes(word: str) -> Tuple[bytes, ...]:\n",
    "    \"\"\"Convert a word into tuple of 1-byte bytes objects.\"\"\"\n",
    "    b = word.encode(\"utf-8\")\n",
    "    return tuple(b[i:i+1] for i in range(len(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23b87d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'c', b'a', b'f', b'\\xc3', b'\\xa9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_bytes(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e6eefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(b'l', b'o', b'w'): 5, (b'l', b'o', b'w', b'e', b'r'): 2, (b'w', b'i', b'd', b'e', b's', b't'): 3, (b'n', b'e', b'w', b'e', b's', b't'): 6}\n"
     ]
    }
   ],
   "source": [
    "# vocab maps tuple-of-byte-symbols → frequency\n",
    "vocab: Dict[Tuple[bytes, ...], int] = {\n",
    "    split_bytes(w): c for w, c in word_freq.items()\n",
    "}\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50e981ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(vocab: Dict[Tuple[bytes, ...], int]) -> Counter:\n",
    "    \"\"\"\n",
    "    Count frequency of every adjacent pair of symbols in the vocab,\n",
    "    weighed by he word frequency.\n",
    "    \"\"\"\n",
    "    stats = Counter()\n",
    "    for symbols, freq in vocab.items():\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pair = (symbols[i], symbols[i + 1])\n",
    "            stats[pair] += freq\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01dcd343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(b'e', b's'): 9, (b's', b't'): 9, (b'w', b'e'): 8, (b'l', b'o'): 7, (b'o', b'w'): 7, (b'n', b'e'): 6, (b'e', b'w'): 6, (b'w', b'i'): 3, (b'i', b'd'): 3, (b'd', b'e'): 3, (b'e', b'r'): 2})\n"
     ]
    }
   ],
   "source": [
    "stats = get_stats(vocab)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e33592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_pair(stats: Counter) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Pick the most frequent pair\n",
    "    Tie-break with lexicographically greater pair\n",
    "    \"\"\"\n",
    "    return max(stats.items(), key=lambda kv: (kv[1], kv[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54bbc522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b's', b't')\n"
     ]
    }
   ],
   "source": [
    "most_freq_pair = choose_pair(stats)\n",
    "print(most_freq_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf696780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair_in_word(\n",
    "    symbols: Tuple[bytes, ...],\n",
    "    pair: Tuple[bytes, bytes],\n",
    "    new_symbol: bytes,\n",
    ") -> Tuple[bytes, ...]:\n",
    "    \"\"\"\n",
    "    Replace every occurence of `pair` in `symbols` with the single symbol `new_symbol`\n",
    "    \"\"\"\n",
    "    a, b = pair\n",
    "    out: List[bytes] = []\n",
    "    i = 0\n",
    "    while i < len(symbols):\n",
    "        if i < len(symbols) - 1 and symbols[i] == a and symbols[i+1] == b:\n",
    "            out.append(new_symbol)\n",
    "            i += 2\n",
    "        else:\n",
    "            out.append(symbols[i])\n",
    "            i += 1\n",
    "    return tuple(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeef4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_merge(\n",
    "    vocab: Dict[Tuple[bytes, ...], int], \n",
    "    pair: Tuple[bytes, bytes],\n",
    ") -> Tuple[Dict[Tuple[bytes, ...], int], bytes]:\n",
    "    \"\"\"\n",
    "    Merge `pair` into a new symbol (their byte concatenation) everywhere.\n",
    "    \"\"\"\n",
    "    a, b = pair\n",
    "    new_symbol = a + b\n",
    "    new_vocab: Dict[Tuple[bytes, ...], int] = {}\n",
    "    for word, freq in vocab.items():\n",
    "        new_word = merge_pair_in_word(word, pair, new_symbol)\n",
    "        new_vocab[new_word] = freq\n",
    "    return new_vocab, new_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c55de9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_train(vocab: Dict[Tuple[bytes, ...], int], num_merges: int):\n",
    "    \"\"\"\n",
    "    Run BPE for `num_merges` stes.\n",
    "    Returns final vocab and the list of merges (pair, new_symbol)\n",
    "    \"\"\"\n",
    "    merges: List[Tuple[Tuple[bytes, bytes], bytes]] = []\n",
    "    for _ in range(num_merges):\n",
    "        stats = get_stats(vocab)\n",
    "        pair = choose_pair(stats)\n",
    "        vocab, new_symbol = apply_merge(vocab, pair)\n",
    "        merges.append((pair, new_symbol))\n",
    "    return vocab, merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1955cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "final_vocab, merges = bpe_train(vocab, num_merges=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "707bc687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merges:\n",
      "('s', 't') -> 'st'\n",
      "('e', 'st') -> 'est'\n",
      "('o', 'w') -> 'ow'\n",
      "('l', 'ow') -> 'low'\n",
      "('w', 'est') -> 'west'\n",
      "('n', 'e') -> 'ne'\n"
     ]
    }
   ],
   "source": [
    "print(\"Merges:\")\n",
    "for pair, new_symbol in merges:\n",
    "    a, b = pair\n",
    "    print(\n",
    "        f\"({a.decode('utf-8')!r}, {b.decode('utf-8')!r}) \"\n",
    "        f\"-> {new_symbol.decode('utf-8')!r}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aefae5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_encode(word: str, merges: List[Tuple[Tuple[bytes, bytes], bytes]]) -> Tuple[bytes, ...]:\n",
    "    \"\"\"\n",
    "    Encode a word with the learned merges.\n",
    "    Returns a list of byte symbols\n",
    "    \"\"\"\n",
    "    symbols = split_bytes(word)\n",
    "    for pair, new_symbol in merges:\n",
    "        symbols = merge_pair_in_word(symbols, pair, new_symbol)\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e969c7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization of 'newest': ['ne', 'west']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "new = \"newest\"\n",
    "encoded_new = bpe_encode(new, merges)\n",
    "print(f\"Tokenization of '{new}':\", [s.decode(\"utf-8\") for s in encoded_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e32fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
